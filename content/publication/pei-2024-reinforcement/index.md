---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: Reinforcement learning for decision-making under deep uncertainty
subtitle: ''
summary: ''
authors:
- Zhihao Pei
- Angela M Rojas-Arevalo
- Fjalar J de Haan
- Nir Lipovetzky
- Enayat A Moallemi
tags: []
categories: []
date: '2024-05-01'
lastmod: 2024-08-27T18:36:10+10:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2024-08-27T08:36:10.916615Z'
publication_types:
- '2'
abstract: 'Planning under complex uncertainty often asks for plans that can adapt to changing future conditions. To inform plan development during this process, exploration methods have been used to explore the performance of candidate policies given uncertainties. Nevertheless, these methods hardly enable adaptation by themselves, so extra efforts are required to develop the final adaptive plans, hence compromising the overall decision-making efficiency. This paper introduces Reinforcement Learning (RL) that employs closed-loop control as a new exploration method that enables automated adaptive policy-making for planning under uncertainty. To investigate its performance, we compare RL with a widely-used exploration method, Multi-Objective Evolutionary Algorithm (MOEA), in two hypothetical problems via computational experiments. Our results indicate the complementarity of the two methods. RL makes better use of its exploration history, hence always providing higher efficiency and providing better policy robustness in the presence of parameter uncertainty. MOEA quantifies objective uncertainty in a more intuitive way, hence providing better robustness to objective uncertainty. These findings will help researchers choose appropriate methods in different applications.

'
publication: '*Journal of Environmental Management*'
links:
- name: URL
  url: https://www.sciencedirect.com/science/article/pii/S030147972400954X
---
